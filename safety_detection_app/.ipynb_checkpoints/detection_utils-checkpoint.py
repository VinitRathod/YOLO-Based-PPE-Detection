{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0681eda-efff-4cf5-a18a-ce7f799c4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import winsound\n",
    "import sys\n",
    "\n",
    "yolov5_path = Path(\"D:/University Of Regina/3rd Semester/CS713/CS713 Project/safety_detection_app/yolov5\").absolute()\n",
    "sys.path.append(str(yolov5_path))\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from utils.augmentations import letterbox\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "class SafetyGearDetector:\n",
    "    def __init__(self, weights_path):\n",
    "        # Initialize model\n",
    "        self.device = select_device('0')\n",
    "        self.model = attempt_load(weights_path, device=self.device)\n",
    "        self.model.half()  # FP16\n",
    "        \n",
    "        # Class names and thresholds\n",
    "        self.class_names = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', \n",
    "                           'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']\n",
    "        \n",
    "        self.conf_thres = {\n",
    "            'Hardhat': 0.9,\n",
    "            'NO-Hardhat': 0.6,\n",
    "            'Mask': 0.5,\n",
    "            'NO-Mask': 0.5,\n",
    "            'NO-Safety Vest': 0.5,\n",
    "            'Person': 0.7,\n",
    "            'Safety Cone': 0.8,\n",
    "            'Safety Vest': 0.85,\n",
    "            'machinery': 0.9,\n",
    "            'vehicle': 0.7\n",
    "        }\n",
    "        \n",
    "        self.default_conf = 0.25\n",
    "        self.last_alert_time = 0\n",
    "        self.alert_cooldown = 5  # Seconds between alerts\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        # Preprocess with letterbox\n",
    "        img = letterbox(frame, new_shape=640, auto=True)[0]\n",
    "        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(self.device)\n",
    "        img = img.half() / 255.0\n",
    "        img = img.unsqueeze(0)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(img)[0]\n",
    "            pred = non_max_suppression(pred, 0.1, 0.4)\n",
    "        \n",
    "        safety_violation = False\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Post-process with class-specific thresholds\n",
    "        for det in pred:\n",
    "            if len(det):\n",
    "                filtered_det = []\n",
    "                for *xyxy, conf, cls in det:\n",
    "                    class_name = self.class_names[int(cls)]\n",
    "                    threshold = self.conf_thres.get(class_name, self.default_conf)\n",
    "                    if conf >= threshold:\n",
    "                        filtered_det.append([*xyxy, conf, cls])\n",
    "                        if class_name in ['NO-Hardhat', 'NO-Mask', 'NO-Safety Vest']:\n",
    "                            safety_violation = True\n",
    "                \n",
    "                if filtered_det:\n",
    "                    filtered_det = torch.tensor(filtered_det).to(self.device)\n",
    "                    filtered_det[:, :4] = scale_boxes(img.shape[2:], filtered_det[:, :4], frame.shape).round()\n",
    "                    \n",
    "                    for *xyxy, conf, cls in filtered_det:\n",
    "                        class_name = self.class_names[int(cls)]\n",
    "                        confidence = float(conf)\n",
    "                        \n",
    "                        if 'NO-' in class_name:\n",
    "                            color = (0, 0, 255)\n",
    "                            cv2.putText(frame, \"!\", (int(xyxy[2])+5, int(xyxy[1])+15), \n",
    "                                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                        else:\n",
    "                            color = (0, 255, 0)\n",
    "                        \n",
    "                        cv2.rectangle(frame, \n",
    "                                     (int(xyxy[0]), int(xyxy[1])),\n",
    "                                     (int(xyxy[2]), int(xyxy[3])),\n",
    "                                     color, 2)\n",
    "                        \n",
    "                        label = f'{class_name} {confidence:.2f}'\n",
    "                        cv2.putText(frame, label,\n",
    "                                   (int(xyxy[0]), int(xyxy[1]) - 10),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                   0.5, color, 2)\n",
    "        \n",
    "        # Trigger alerts if needed\n",
    "        if safety_violation and (current_time - self.last_alert_time) > self.alert_cooldown:\n",
    "            winsound.Beep(1000, 500)\n",
    "            warning_text = \"SAFETY VIOLATION DETECTED!\"\n",
    "            text_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "            text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "            text_y = (frame.shape[0] + text_size[1]) // 2\n",
    "            cv2.putText(frame, warning_text, (text_x, text_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            self.last_alert_time = current_time\n",
    "        \n",
    "        return frame, safety_violation\n",
    "\n",
    "    def process_video(self, video_path, output_path=None):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            return None\n",
    "        \n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            processed_frame, _ = self.detect(frame)\n",
    "            frames.append(processed_frame)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        if output_path:\n",
    "            # Save processed video\n",
    "            height, width = frames[0].shape[:2]\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, 20.0, (width, height))\n",
    "            for frame in frames:\n",
    "                out.write(frame)\n",
    "            out.release()\n",
    "        \n",
    "        return frames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
