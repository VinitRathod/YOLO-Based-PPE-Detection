{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4b4eaf-35ea-4235-baeb-f73d79e5be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0913b51b-f498-4fa4-ba1f-c7f5cf60dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n",
      "True\n",
      "12.1\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)          # Should show CUDA 12.x (e.g., 2.0.1+cu121)\n",
    "print(torch.cuda.is_available())  # Must return True\n",
    "print(torch.version.cuda)         # Should match your CUDA version (e.g., 12.1)\n",
    "print(torch.cuda.get_device_name(0))  # Should show \"RTX 4070\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f19a8c-e589-45e8-a419-aaa6bf391915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Local Disk\n",
      " Volume Serial Number is AC16-1EFB\n",
      "\n",
      " Directory of D:\\University Of Regina\\3rd Semester\\CS713\\CS713 Project\n",
      "\n",
      "2025-06-07  01:42 PM    <DIR>          .\n",
      "2025-06-05  03:44 PM    <DIR>          ..\n",
      "2025-06-05  03:51 PM    <DIR>          .idea\n",
      "2025-06-05  04:05 PM    <DIR>          .ipynb_checkpoints\n",
      "2025-06-05  03:53 PM    <DIR>          .virtual_documents\n",
      "2025-06-05  03:52 PM    <DIR>          anaconda_projects\n",
      "2025-06-05  03:44 PM       973,951,114 dataset.zip\n",
      "2025-06-05  05:37 PM    <DIR>          datasets\n",
      "2025-06-07  01:42 PM             4,176 ObjectDetection.ipynb\n",
      "2025-06-05  06:39 PM    <DIR>          PPE detection\n",
      "2025-06-05  05:37 PM    <DIR>          yolov5\n",
      "2025-06-06  02:17 PM        14,808,437 yolov5s.pt\n",
      "               3 File(s)    988,763,727 bytes\n",
      "               9 Dir(s)  601,601,818,624 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfec27bd-1ce6-4b8d-abfb-c707900f8322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-6-5 Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Set YOLOv5 path (UPDATE THIS)\n",
    "yolov5_path = Path(\"D:/University Of Regina/3rd Semester/CS713/CS713 Project/yolov5\").absolute()\n",
    "sys.path.append(str(yolov5_path))\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from utils.augmentations import letterbox\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "# Load model\n",
    "device = select_device('0')\n",
    "model = attempt_load('yolov5/runs/train/exp13/weights/best.pt', device=device)\n",
    "model.half()  # FP16\n",
    "\n",
    "# Class names (UPDATE THESE TO MATCH YOUR data.yaml)\n",
    "# class_names= ['glove', 'goggles', 'helmet', 'mask', 'no-suit', 'no_glove', 'no_goggles', 'no_helmet', 'no_mask', 'no_shoes', 'shoes', 'suit']\n",
    "class_names= ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']\n",
    "\n",
    "# Camera setup\n",
    "cap = cv2.VideoCapture(0)  # Or RTSP/HTTP stream URL\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Preprocess with letterbox\n",
    "    img = letterbox(frame, new_shape=640, auto=True)[0]\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.half() / 255.0\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)[0]\n",
    "        pred = non_max_suppression(pred, 0.25, 0.4)\n",
    "    \n",
    "    # Post-process and draw boxes with class names\n",
    "    for det in pred:\n",
    "        if len(det):\n",
    "            det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], frame.shape).round()\n",
    "            for *xyxy, conf, cls in det:\n",
    "                # Get class name and confidence\n",
    "                class_name = class_names[int(cls)]\n",
    "                confidence = float(conf)\n",
    "                \n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(frame, \n",
    "                             (int(xyxy[0]), int(xyxy[1])),\n",
    "                             (int(xyxy[2]), int(xyxy[3])),\n",
    "                             (0, 255, 0), 2)\n",
    "                \n",
    "                # Put class label and confidence\n",
    "                label = f'{class_name} {confidence:.2f}'\n",
    "                cv2.putText(frame, label,\n",
    "                           (int(xyxy[0]), int(xyxy[1]) - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                           0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Safety Gear Detection', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb0ae86e-ec5c-4c71-8513-c4a88329e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-6-5 Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Set YOLOv5 path\n",
    "yolov5_path = Path(\"D:/University Of Regina/3rd Semester/CS713/CS713 Project/yolov5\").absolute()\n",
    "sys.path.append(str(yolov5_path))\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from utils.augmentations import letterbox\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "# Load model\n",
    "device = select_device('0')\n",
    "model = attempt_load('yolov5/runs/train/exp13/weights/best.pt', device=device)\n",
    "model.half()  # FP16\n",
    "\n",
    "# Class names and their specific confidence thresholds\n",
    "class_names = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', \n",
    "               'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']\n",
    "\n",
    "# Class-specific confidence thresholds\n",
    "conf_thres = {\n",
    "    'Hardhat': 0.9,\n",
    "    'NO-Hardhat': 0.6,  # Lower threshold to catch more violations\n",
    "    'Mask': 0.95,\n",
    "    'NO-Mask': 0.5,\n",
    "    'NO-Safety Vest': 0.5,\n",
    "    'Person': 0.7,\n",
    "    'Safety Cone': 0.8,\n",
    "    'Safety Vest': 0.85,\n",
    "    'machinery': 0.9,\n",
    "    'vehicle': 0.7\n",
    "}\n",
    "\n",
    "# Default threshold for classes not in conf_thres\n",
    "default_conf = 0.25\n",
    "\n",
    "# Camera setup\n",
    "cap = cv2.VideoCapture(0)  # Or RTSP/HTTP stream URL\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Preprocess with letterbox\n",
    "    img = letterbox(frame, new_shape=640, auto=True)[0]\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.half() / 255.0\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)[0]\n",
    "        # Initial NMS with low threshold\n",
    "        pred = non_max_suppression(pred, 0.1, 0.4)\n",
    "    \n",
    "    # Post-process with class-specific thresholds\n",
    "    for det in pred:\n",
    "        if len(det):\n",
    "            # Apply class-specific thresholds\n",
    "            filtered_det = []\n",
    "            for *xyxy, conf, cls in det:\n",
    "                class_name = class_names[int(cls)]\n",
    "                threshold = conf_thres.get(class_name, default_conf)\n",
    "                if conf >= threshold:\n",
    "                    filtered_det.append([*xyxy, conf, cls])\n",
    "            \n",
    "            # Convert back to tensor\n",
    "            if filtered_det:\n",
    "                filtered_det = torch.tensor(filtered_det).to(device)\n",
    "                # Scale boxes to original image\n",
    "                filtered_det[:, :4] = scale_boxes(img.shape[2:], filtered_det[:, :4], frame.shape).round()\n",
    "                \n",
    "                # Draw boxes\n",
    "                for *xyxy, conf, cls in filtered_det:\n",
    "                    class_name = class_names[int(cls)]\n",
    "                    confidence = float(conf)\n",
    "                    \n",
    "                    # Custom colors for different classes\n",
    "                    if 'NO-' in class_name:  # Violations in red\n",
    "                        color = (0, 0, 255)\n",
    "                    elif class_name in ['Hardhat', 'Safety Vest']:  # PPE in green\n",
    "                        color = (0, 255, 0)\n",
    "                    else:  # Others in blue\n",
    "                        color = (255, 0, 0)\n",
    "                    \n",
    "                    cv2.rectangle(frame, \n",
    "                                 (int(xyxy[0]), int(xyxy[1])),\n",
    "                                 (int(xyxy[2]), int(xyxy[3])),\n",
    "                                 color, 2)\n",
    "                    \n",
    "                    label = f'{class_name} {confidence:.2f}'\n",
    "                    cv2.putText(frame, label,\n",
    "                               (int(xyxy[0]), int(xyxy[1]) - 10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                               0.5, color, 2)\n",
    "    \n",
    "    cv2.imshow('Safety Gear Detection', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29610d7b-f086-4871-b79b-ae699e478890",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1695550110.py, line 104)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 104\u001b[1;36m\u001b[0m\n\u001b[1;33m    else class_name in ['Hardhat', 'Safety Vest']:  # PPE in green\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import winsound  # For Windows alert sounds\n",
    "import time\n",
    "\n",
    "# Set YOLOv5 path\n",
    "yolov5_path = Path(\"D:/University Of Regina/3rd Semester/CS713/CS713 Project/yolov5\").absolute()\n",
    "sys.path.append(str(yolov5_path))\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "from utils.augmentations import letterbox\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "# Load model\n",
    "device = select_device('0')\n",
    "model = attempt_load('yolov5/runs/train/exp13/weights/best.pt', device=device)\n",
    "model.half()  # FP16\n",
    "\n",
    "# Class names and their specific confidence thresholds\n",
    "class_names = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', \n",
    "               'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']\n",
    "\n",
    "# Class-specific confidence thresholds\n",
    "conf_thres = {\n",
    "    'Hardhat': 0.9,\n",
    "    'NO-Hardhat': 0.6,  # Lower threshold to catch more violations\n",
    "    'Mask': 0.5,\n",
    "    'NO-Mask': 0.5,\n",
    "    'NO-Safety Vest': 0.5,\n",
    "    'Person': 0.7,\n",
    "    'Safety Cone': 0.8,\n",
    "    'Safety Vest': 0.85,\n",
    "    'machinery': 0.9,\n",
    "    'vehicle': 0.7\n",
    "}\n",
    "\n",
    "# Default threshold for classes not in conf_thres\n",
    "default_conf = 0.25\n",
    "\n",
    "# Alert parameters\n",
    "last_alert_time = 0\n",
    "alert_cooldown = 5  # Seconds between alerts\n",
    "\n",
    "# Camera setup\n",
    "cap = cv2.VideoCapture(0)  # Or RTSP/HTTP stream URL\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Preprocess with letterbox\n",
    "    img = letterbox(frame, new_shape=640, auto=True)[0]\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.half() / 255.0\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)[0]\n",
    "        # Initial NMS with low threshold\n",
    "        pred = non_max_suppression(pred, 0.1, 0.4)\n",
    "    \n",
    "    # Initialize violation flags\n",
    "    safety_violation = False\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Post-process with class-specific thresholds\n",
    "    for det in pred:\n",
    "        if len(det):\n",
    "            # Apply class-specific thresholds\n",
    "            filtered_det = []\n",
    "            for *xyxy, conf, cls in det:\n",
    "                class_name = class_names[int(cls)]\n",
    "                threshold = conf_thres.get(class_name, default_conf)\n",
    "                if conf >= threshold:\n",
    "                    filtered_det.append([*xyxy, conf, cls])\n",
    "                    if class_name in ['NO-Hardhat', 'NO-Mask', 'NO-Safety Vest']:\n",
    "                        safety_violation = True\n",
    "            \n",
    "            # Convert back to tensor\n",
    "            if filtered_det:\n",
    "                filtered_det = torch.tensor(filtered_det).to(device)\n",
    "                # Scale boxes to original image\n",
    "                filtered_det[:, :4] = scale_boxes(img.shape[2:], filtered_det[:, :4], frame.shape).round()\n",
    "                \n",
    "                # Draw boxes\n",
    "                for *xyxy, conf, cls in filtered_det:\n",
    "                    class_name = class_names[int(cls)]\n",
    "                    confidence = float(conf)\n",
    "                    \n",
    "                    # Custom colors for different classes\n",
    "                    if 'NO-' in class_name:  # Violations in red\n",
    "                        color = (0, 0, 255)\n",
    "                        # Draw warning symbol for violations\n",
    "                        cv2.putText(frame, \"!\", (int(xyxy[2])+5, int(xyxy[1])+15), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        color = (0,255,0)\n",
    "                    # else class_name in ['Hardhat', 'Safety Vest']:  # PPE in green\n",
    "                    #     color = (0, 255, 0)\n",
    "                    # else:  # Others in blue\n",
    "                    #     color = (255, 0, 0)\n",
    "                    \n",
    "                    cv2.rectangle(frame, \n",
    "                                 (int(xyxy[0]), int(xyxy[1])),\n",
    "                                 (int(xyxy[2]), int(xyxy[3])),\n",
    "                                 color, 2)\n",
    "                    \n",
    "                    label = f'{class_name} {confidence:.2f}'\n",
    "                    cv2.putText(frame, label,\n",
    "                               (int(xyxy[0]), int(xyxy[1]) - 10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                               0.5, color, 2)\n",
    "    \n",
    "    # Trigger alerts for safety violations\n",
    "    if safety_violation and (current_time - last_alert_time) > alert_cooldown:\n",
    "        # Play alert sound (Windows)\n",
    "        winsound.Beep(1000, 500)  # Frequency: 1000Hz, Duration: 500ms\n",
    "        \n",
    "        # Display full-screen warning\n",
    "        warning_text = \"SAFETY VIOLATION DETECTED!\"\n",
    "        text_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "        text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "        text_y = (frame.shape[0] + text_size[1]) // 2\n",
    "        cv2.putText(frame, warning_text, (text_x, text_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        last_alert_time = current_time\n",
    "    \n",
    "    # Display frame\n",
    "    cv2.imshow('Safety Gear Detection', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
